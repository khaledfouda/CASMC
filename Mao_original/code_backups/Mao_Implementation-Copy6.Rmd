---
title: "Mao's Method Implementation"
output:
  html_document: default
  pdf_document: default
date: "2023-11-14"
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```


```{r , include=TRUE, eval=TRUE, message=FALSE,warning=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(magrittr)
require(foreach)
require(doParallel)
library(ggplot2)
library(hexbin)
library(patchwork)
```

## References:

1. Matrix Completion With Covariate Information by Xiaojun Mao et al.
2. Matrix completion based on side information by Youssef

## Notes:
- Formulas with ids in the form ([0-9]*) have the same ids in the Mao's paper.  


We consider a matrix of interest $A \in \Re^{n_1\times n_2}$ with row covariates $X  \in \Re ^{n_1 \times m}$ and the model

$$
A = X \beta + B
$$

where $B$ is a low rank matrix and orthogonal to $X$. 
We assume that we don't fully observe $A_0$ and that we have a partially observed (corrupted) version of it called $Y$.
This follows the model 

$$
Y_{ij} = A_{ij} + \epsilon_{ij}
$$

where $\epsilon_{ij}$ are i.i.d normal with 0 mean and finite variance.

We consider the sampling indicator $w_{ij}=1$ if $Y_{ij}$ is observed and 0 otherwise. $w_{ij}$ is independent from $\epsilon_{ij}$.

In Mao's paper, the the sampling (missingness) probabilities may depend on the variate and are modeled as 
$$ w_{ij} \sim Bernoulli(\theta_{ij}(x_i))$$
The loss function in (5) consists of the the minimizer $\hat{R}^*$, $L_2$ regularization on $\beta$ and $B$ as well as $L_1$ regularization on $B$. 

$$
\begin{aligned}
&f(\beta, B, \lambda_1, \lambda_2, \alpha) = \hat{R}^*(\beta,B) + \lambda_1 ||\beta||^2_F + \lambda_2(\alpha ||B||_* + (1-\alpha||B||^2_F))  \text{        }&&(5) \\
&\hat{R}^*(\beta,B) = \frac{1}{n_1n_2} \{||X\beta - P_x \text{ } big(W*\hat\theta^**Y) ||^2_F+|| B - P_{\overline x}(W * \hat\theta^* * Y) ||^2_F \} && (4)
\end{aligned}
$$


In the code below, and based on the loss function defined in (5) and (4), we estimate $\beta$, $B$ using formulas (8) and (11) as written below:

$$
\begin{aligned}
\hat{\beta} &= (X^TX + n_1n_2\lambda_1 I_{m})^{-1} X^T (W * \hat\theta^* *Y)\text{        }&&(8)\\
\hat{B} &= \frac{1}{1+2(1-\alpha) n_1n_2\lambda_2} T_{\alpha n_1 n_2 \lambda_2}(P_{\overline x}(W * \hat\theta^* *Y))\text{        }&&(11)
\end{aligned}
$$
Where $\lambda_1,\lambda_2, \alpha$ are the regularization hyperparameters for $\beta$ and $B$, and
$$
\begin{aligned}
 &\hat\theta^* = {\hat\theta_{ij}^{-1}(x_i) = {(expit((1,x_i^T)\gamma_{ij}))}^{-1}}\text{        }&&(a)\\
&T_c(D) = U \times Diag\{(\sigma_i-c)_+\}\times V^T\text{        }&&(b)\\
&P_{\overline x} = 1 - P_{X}\text{        }&&(c)\\
&P_{X} = X(X^TX)^{-1}X^T\text{        }&&(d)
\end{aligned}
$$

----------------------

## 1) Implementation with fixed $\lambda_1, \lambda_2,  \alpha$ 

The following function estimates $\hat\beta$ and $\hat B$ as above with fixed (given) hyperparameters. I will try to use the same notations as above to avoid confusion.

```{r eval=TRUE}
theta_default <- function(X, W, ...){
  # using logistic regression as indicated in (a)
  n1 = dim(W)[1]
  n2 = dim(W)[2]
  theta_hat = matrix(NA, n1, n2)
  for(j in 1:n2){
    model_data = data.frame(cbind(W[,j], X))
    model_fit = glm(X1~., family=binomial(), data=model_data)
    theta_hat[, j] = 1 / predict(model_fit, type="response")
  }
  return(theta_hat)
}
theta_random <- function(Y, ...){
  # A theta estimation function that selects the proportion of missing data within the same column
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  theta_hat = matrix(NA, n1, n2)
  for(j in 1:n2){
    theta_hat[,j] = n1 / sum(Y[,j]==0) 
  }
  return(theta_hat)
}
theta_simple <- function(Y, ...){
  # A theta estimation function that selects the proportion of missing data in the matrix
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  theta_hat = matrix(n1 / sum(Y==0), n1, n2)
  return(theta_hat)
}


Mao.fit <- function(Y, X, lambda.1, lambda.2, alpha, n1n2_optimized=TRUE, theta_estimator=theta_random){
  #
  #' ----------------------------------------------
  #' Input: Y: partially observed A,
  #'         X: covariate matrix
  #'         lambda.1, lambda.2, alpha: hyperparameters
  #' ----------------------------------------------
  #' output: list of  A, Beta_hat, B_hat
  #' ----------------------------------------------
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  m  = dim(X)[2]
  
  W = matrix(as.numeric(Y!=0), n1, n2)
  # The following two lines are as shown in (c) and (d)
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 
  
  if(n1n2_optimized == TRUE){
    # we define the factor that will be used later:
    n1n2 = svd(t(X) %*% X)$d[1] # n1 * n2
  }else{
    n1n2 = n1 * n2
  }
  
  # The following part estimates theta (missingness probabilities)
  theta_hat = theta_estimator(W=W, X=X, Y=Y)
  # the following is the product of W * theta_hat * Y
  W_theta_Y = Y * theta_hat # * W 

  # beta hat as (8)
  beta_hat = solve(t(X) %*% X + n1n2 * lambda.1 * diag(1, m)) %*% t(X) %*% W_theta_Y
  # SVD decomposition to be used in (b)
  svdd = svd(P_bar_X %*% W_theta_Y)
  if(n1n2_optimized == TRUE){
    # evaluation of  (b)
    n1n2 = svdd$d[1]
  }else{
    n1n2 = n1 * n2
  }
  T_c_D = svdd$u %*% (pmax(svdd$d - alpha*n1n2*lambda.2, 0) * t(svdd$v))
  # B hat as in (11)
  B_hat = (1 + 2 * (1-alpha) * n1n2 * lambda.2 )^(-1) * T_c_D
  # computing the rank of B [Copied from Mao's code; Don't understand how it works.]
  rank = sum(pmax(svdd$d - n1n2 * lambda.2 * alpha, 0) > 0) + m
  
  # Estimate the matrix as given in the model at the top
   A_hat = X %*% beta_hat + B_hat
  
  return(list(A_hat = A_hat, B_hat = B_hat, beta_hat = beta_hat, rank = rank))
}

```


-----------------------------------------------------------


## 2) Hyperparameter Optimization

Hyperparameter optimization for $\lambda_1,\lambda_2,\alpha$ is done using k-fold (k=5 by default) and grid search. Mao's paper optimizes for each parameter separately while fixing the other two. The explored/recommended the range of (0-2) for $\lambda_1$, (0.1,0.9) for $lambda_2$, and (0.992,1) for $\alpha$.



```{r eval=TRUE}
prepare_fold_data <- function(Y, X, W, A, n1n2_optimized, theta_estimator) {
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  m  = dim(X)[2]
  
  # The following two lines are as shown in (c) and (d)
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 

  theta_hat = theta_estimator(W=W, X=X, Y=Y)
  
  #---------
  # The following are partial parts of equations 8 and 11 that don't involve the hyperparameters.
  # this is useful to avoid unneccessary matrix multiplications.
  #----------
  X.X = t(X) %*% X
  if(n1n2_optimized == TRUE){
    # this one is for equation 8, the product n1n2 is replace with the Eigen value
    n1n2Im = svd(t(X) %*% X)$d[1]  * diag(1, m)  
  }else{
    n1n2Im = n1 * n2  * diag(1, m)
  }
  # the following is the product of W * theta_hat * Y
  W_theta_Y = Y * theta_hat
  X.W.theta.Y = t(X) %*% W_theta_Y
  svdd = svd(P_bar_X %*% W_theta_Y)
  if(n1n2_optimized == TRUE){
    # this one is for equation 11, the product is also replace with the Eigen value of the SVD
    n1n2 = svdd$d[1]
  }else{
    n1n2 = n1 * n2
  }
    
  return(list(A.test=A[W==0], W=W, X=X, X.X=X.X, n1n2Im=n1n2Im, n1n2=n1n2,
              X.W.theta.Y = X.W.theta.Y, svdd=svdd))
}

Mao.fit_optimized <- function(data, lambda.1, lambda.2, alpha){
  beta_hat = solve( data$X.X + data$n1n2Im * lambda.1) %*% data$X.W.theta.Y

  T_c_D = data$svdd$u %*% (pmax(data$svdd$d - alpha*data$n1n2*lambda.2, 0) * t(data$svdd$v))
  # B hat as in (11)
  B_hat = (1 + 2 * (1-alpha) * data$n1n2 * lambda.2 )^(-1) * T_c_D
  # Estimate the matrix as given in the model at the top
   A_hat = data$X %*% beta_hat + B_hat
  
  return(A_hat[data$W == 0])
}

```


```{r eval=TRUE}
Mao.cv <- function(A, X, W, n_folds=5, lambda.1_grid = seq(0,1,length=30),
                   lambda.2_grid = seq(0.9, 0.1, length=30),
                   alpha_grid = seq(0.992, 1, length=20), seed=2023, numCores=16, n1n2_optimized=TRUE,
                   theta_estimator=theta_random){
  
  #' -------------------------------------------------------------------
  #' Input :
  #' A : Complete (True) A matrix as in the model above of size n1 by n2
  #' X :  Covariate matrix of size  n1 by m
  #' W : Binary matrix representing the mask. wij=1 if yij is observed. size similar to A
  #' The rest are cross validation parameters
  #' --------------------------------------------------------------------
  #' Output:
  #' list of best parameters and best score (minimum average MSE across folds)
  #' --------------------------------------------------------------------

  Y = A * W
  
  set.seed(seed = seed)
  indices = sample(cut(seq(1, nrow(A)), breaks=n_folds, labels=FALSE))
  best_score = Inf
  best_params = list(alpha = NA, lambda.1 = NA, lambda.2 = NA)
  
  fold_data = lapply(1:n_folds, function(i) {
    train_indices = which(indices != i, arr.ind = TRUE)
    Y_train = Y[train_indices,]
    X_train = X[train_indices,]
    W_train = W[train_indices,]
    A_train = A[train_indices,]
    prepare_fold_data(Y_train, X_train, W_train, A_train, n1n2_optimized, theta_estimator)
  })
  
  # Original for loop to be executed on one node 
  # *******************************************
  # for(alpha in alpha_grid){
  #   for(lambda.1 in lambda.1_grid){
  #     for(lambda.2 in lambda.2_grid){
  #       
  #       scores = numeric(n_folds)
  #       for(i in 1:n_folds){
  #         data = fold_data[[i]]
  #         #train_indices = which(indices != i, arr.ind=TRUE)
  #         
  #         # compute the estimates with a modified fit function
  #         A_hat = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
  #         #print(dim(A[test_indices,]))
  #         #print(dim(A_hat))
  #         #print(dim(data$X))
  #         # Evaluate model performance using MSE
  #         # IMPORTANT: As this is not a predictive model, the MSE is calculated on the training data
  #         # that is, the test fold isn't used at all.
  #         scores[i] = mean((data$A - A_hat)^2)
  #       }
  #       avg_score = mean(scores)
  #       
  #       if(avg_score < best_score){
  #         best_score = avg_score
  #         best_params = list(alpha=alpha, lambda.1=lambda.1, lambda.2=lambda.2)
  #       }
  #     }
  #   }
  # }
  # ************************************************************
  # prepare the cluster
  cl <- makeCluster(numCores) 
  registerDoParallel(cl)
  # fixing lambda 1 at 0 and optimizing for lambda 2 and alpha using a grid
  lambda.1 = 0
  # Export the Mao.fit_optimized function and any other necessary objects to each worker
  clusterExport(cl, varlist = c("Mao.fit_optimized"))
  results <- foreach(alpha = alpha_grid, .combine = rbind) %:%
    foreach(lambda.2 = lambda.2_grid, .combine = rbind) %dopar% {
      scores = numeric(n_folds)
      for (i in 1:n_folds) {
        data = fold_data[[i]]
        A_hat_test = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
        scores[i] = mean((data$A.test - A_hat_test)^2)
      }
      avg_score = mean(scores)
      c(alpha, lambda.1, lambda.2, avg_score)
    }
  # Process results to find the best parameters
  best_result <- results[which.min(results[, 4]), ]
  best_params <- list(alpha = best_result[1], lambda.1 = best_result[2], lambda.2 = best_result[3])
  best_score <- best_result[4]
  # close the cluster
  stopCluster(cl)
  #--------------------------------------------
  # fixing optimal values of lambda 2 and alpha and optimizing for lambda 1 separately
  lambda.2 = best_params$lambda.2
  alpha = best_params$alpha
  for(lambda.1 in lambda.1_grid){
    scores = numeric(n_folds)
    for(i in 1:n_folds){
      data = fold_data[[i]]
      # compute the estimates with a modified fit function
      A_hat_test = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
      # Evaluate model performance using MSE
      # IMPORTANT: As this is not a predictive model, the MSE is calculated on the training data
      # that is, the test fold isn't used at all.
      scores[i] = mean((data$A.test - A_hat_test)^2)
    }
    avg_score = mean(scores)

    if(avg_score < best_score){
      best_score = avg_score
      best_params$alpha = alpha
    }
  }
  #---------------------------------------------------
  return(list(best_parameters = best_params, best_score = best_score))
  
}

```




### Notes regarding parts 1 and 2:

#### 1. $n_1*n_2$ alternative:
  
  I have tested both methods (using the actual $n_1*n_2$ and using the Eigen value formulas provided by Mao) and found that Mao's method     provided easier hyperparameter optimization. Changing method does not affect $\lambda_1$ and has a little but noticeable effect on $\alpha$. However, it has a strong effect on $\lambda_2$. For Mao's approach, the optimal $\lambda_2$ is always found somewhere between 0.1 and 0.9. However, when replacing it with $n_1*n_2$, the optimal $\lambda_2$ becomes very large. Cross-validation always selected the highest value of $\lambda_2$ provided. I stopped testing at $\lambda_2=100$ where the optimal value was still larger than that. 


#### 2. Grid optimization vs separate optimization:

  As I said, Mao's cross-validation function optimized each parameter separetly while I initially used a grid of the 3 parameters. To  compare the approaches, I fixed two parameters at optimal values and then optimized for the third. After that, I fixed them at non-optimal values and then optimized for the third. If the two results are equal, then the third parameter doesn't depend on the other two parameters. I found that $\lambda_1$ does not depend on either $\lambda_2$ or $\alpha$. However, $\lambda_2$ and $\alpha$ depend on the value of the other and hence needed to be optimized together. My final solution is to first set $\lambda_1=0$ (the reason is mentioned later) and optimized for $\lambda_2$ and $\alpha$ together using a grid. After finding their optimal values, I set them to their optimal values and optimize for $\lambda_1$. I used parallel computing (number of cores = 8 by default) for the grid optimization and a simple for loop for $\lambda_1$ optimization.

#### 3. Logistic Model for estimating the probabilities of missingness:

Mao's paper proposed a logistic model to estimate the probabilities of missingness using the matrix of covariates. His empirical study involved a dataset where these probabilities were dependent on some of the covariates (age group and gender). However, for genetic methylation, we don't expect that. I experimented with the suggested logistic model ($theta\_default()$), using the proportion of missing values within the same column ($theta\_random()$), and using a single value representing the proportion of missing values in the whole data ($theta\_simple()$). The results, shown in part (a) of the results section, shows that logistic model > proportion within column > proportion of all data.

#### 4. The subset used as a test set for validation: 

  K-fold cross-validation was used for optimization with a default of 5 folds. Since this is not a predictive model, it was not possible to apply the model on the test fold. Therefore, the score function (MSE) used the missing training values (ie, those with $W_{ij}=0$).

#### 5. Stanrdadization of rows and columns in the dataset

In our simulation and implementation we didn't consider to normalizing the rows and columns to 0 mean and unit variance, which is considered n Mao's paper. This is to be considered later. 

---------------------------------------------------------------------------


## 2) Simulation Test

For simulation, I was presented with 3 models, two defined by Youssef and one by Mao. I will show below the three models, and later for evaluation, I will use the second model by Youssef.

Using the same notations as before, Mao's simulation model is defined as:

$$
\begin{aligned}
Y = X \beta + B + \epsilon = A + \epsilon && (S0)
\end{aligned}
$$
Where $B = P_{\overline x} U V^T$ such that $U \in \Re^{n_1\times r}$ and $V \in \Re^{n_2\times r}$.
Moreover, $X, \beta, U,V \sim Gaussian(0,1)$. The error matrix $\epsilon \in \Re^{n_1\times n_2}\sim Gaussian(0,\sigma^2_\epsilon)$ with $\sigma^2_\epsilon$ is chosen such that the signal-to-noise ratio (SNR) is set to 1. That is

$$ \sigma^2_\epsilon = \frac{\sum(A-\bar A)^2}{n_1n_2-1}$$
Finally, for their simulation, they set $m=20,r=10$ and explored the following values for the matrix dimensions $n1=n2=400,600,800,1000$.
 
 This simulation is defined below in the function $generate\_simulation\_data\_mao()$.
 
 Youssef's simulation involved row and column covariates to adapt to his data. The notations below are diffferent than those used by Youssef. I tried to standardize to Mao's notation style so we don't get confused. Youssef's two models are defined below:

 $$
 \begin{aligned}
 & Y = X \beta_x + (Z\beta_z)^T + P_{\overline x} BP_{\overline z} + \epsilon && (S1)\\
 & Y = X \beta_x + P_{\overline x} B + \epsilon&&(S2)
 \end{aligned} 
 $$
Clearly the first model employs row and column covariates while the second column employs only row covariates. $X \in \Re^{n_1\times m_1}$ will always be associated with row covariates while $Z \in \Re^{n_2\times m_2}$ will be associated with column covariates. 
The coefficients associated with each set of covariates are $\beta_x \in \Re^{m_1\times n_2}$ and $\beta_z \in \Re^{m_2\times n_1}$. The low rank matrix $B=B_xB_z$ is the product of matrices $B_x \in \Re^{n_1\times m_2}$ and $B_z \in \Re^{m_2\times n_2}$.
$ X, Z, \epsilon \sim Gaussian(0,1)$ while $\beta_x, \beta_z, B_x, B_z \sim U(0,1)$
 
 For his simulation, he set $n_1=n_2=300$, $m_1=5$, $m_2=10$ and the missingness probability ranging from $30\%$ to $80\%$. Both models are defined in the function $generate\_simulation\_data\_ysf()$.
 
For the rest of this document, I will be using Youssef's second model (S2). 
 
```{r eval=TRUE}
normalize_matrix <- function(X) {
  # Normalize rows
  X_row_normalized <- t(apply(X, 1, function(row) {
    (row - mean(row)) / sd(row)
  }))
  
  # Normalize columns
  X_col_normalized <- apply(X_row_normalized, 2, function(col) {
    (col - mean(col)) / sd(col)
  })
  
  return(X_col_normalized)
}


# This function generates Mao's simulation as defined in (M0) above. Dimensions, missing probability are given as parameters. 
generate_simulation_data_mao <- function(n1 =400,  n2 = 400, m = 20, r = 10, missing_prob = 0.2, seed=2023){
  set.seed(seed=seed)
  X <- matrix(rnorm(n1*m), ncol = m) #%>% normalize_matrix()
  beta <- matrix(rnorm(m*n2), ncol=n2)
  U <- matrix(rnorm(n1*r),ncol=r)
  V <- matrix(rnorm(n2*r),ncol=r)
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 
  B = P_bar_X %*% U %*% t(V)
  A <- X %*% beta + B
  rank <- qr(A)$rank
  #----------------------------------------------------------
  # Does fully observed Y = A (ie,  without noise?)? In that case ignore the code below.
  #----------------------------------------------------------------------
  # Computing epsilon as iid zero mean Gaussian with variance chosen such that the signal-to-noise ratio (SNR) is 1
  signal_A <- sum((A - mean(A))^2) / (n1 * n2 - 1)
  sigma_epsilon <- sqrt(signal_A)  # Since SNR = 1
  epsilon <- matrix(rnorm(n1 * n2, mean = 0, sd = sigma_epsilon), n1, n2)
  Y <- A + epsilon
  #-----------------------------------------------------------------------------
  W <- matrix( rbinom(n1*n2, 1, (1 - missing_prob) ) , nrow = n1)
  #---------------------------------------------------------------------
  return(list(A=A, W=W, X=X, beta=beta, B=B, rank=rank))
}
# This functions generates either model M1 or M2 from Yousef's simulation. Set model=1 for M1 or model=2 for M2.
generate_simulation_data_ysf <- function(model=1, n1 =300,  n2 = 300, m1 = 5, m2 = 10, missing_prob = 0.7, seed=2023){
  set.seed(seed=seed)
  X <- matrix(rnorm(n1*m1), ncol = m1)
  Z <- matrix(rnorm(n2*m2), ncol = m2)
  E <- matrix(rnorm(n1*n2), ncol = n2)
  # normalize X
  #X <- normalize_matrix(X)
  beta.x <- matrix(runif(m1*n2), ncol=n2)
  beta.z <- matrix(runif(m2*n1), ncol=n1)
  B.x <- matrix(runif(n1*m2), ncol=m2)
  B.z <- matrix(runif(m2*n2), ncol=n2)
  B <- B.x %*% B.z
  
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X
  P_Z = Z %*% solve(t(Z) %*% Z) %*% t(Z)
  P_bar_Z = diag(1,n2) - P_Z
  
  W <- matrix( rbinom(n1*n2, 1, (1 - missing_prob) ) , nrow = n1)
  
  if(model == 1){
    A <- (X %*% beta.x) + t(Z %*% beta.z) + P_bar_X %*% B %*% P_bar_Z + E
    rank <- qr(A)$rank
    return(list(A=A, W=W, X=X, Z=Z, beta.x=beta.x, beta.z=beta.z, B=B, rank=rank))
  }else if (model == 2){
    A <- (X %*% beta.x) + P_bar_X %*% B + E
    rank <- qr(A)$rank
    return(list(A=A, W=W, X=X, beta.x=beta.x, B=B, rank=rank))
  }
  else{
    stop("Error: Unrecognized model.")
  }
  #-----------------------------------------------------------------------------
  #---------------------------------------------------------------------
  
}
```

## 3) Results:

The following function helps in comparing Actual vs Estimated values with a perfect-fit line and a linear-fit line. 

```{r eval=TRUE}
plot_actual.vs.estimated <- function(Actual, Predicted, xlab, ylab,title1="Comparison of Actual and Predicted Values"){
    
  data <- data.frame(
    Actual = as.vector(Actual),
    Predicted = as.vector(Predicted)
  )
  lm_fit <- lm(Predicted ~ Actual, data = data)
  coefficients <- coef(lm_fit)
  
  # Create the equation text
  equation_text <- sprintf("y = %.2fx + %.3f", coefficients[2], coefficients[1])
  
  ggplot(data, aes(x = Actual, y = Predicted)) + 
    geom_hex(color = "grey80",bins=200) +  
    geom_smooth(method = "lm", aes(color = "LM Fit"), se = TRUE) +
    #geom_line(data = data.frame(x = range(data$Actual), y = range(data$Predicted)),
    #          aes(x = x, y = y, linetype = "Perfect Fit"), alpha=0, color = "white") +  
    annotate("text", x = Inf, y = Inf, label = equation_text, hjust = 2.1, size=5, vjust = 3.5, color = "red", size = 2.5) + 
    scale_color_manual("", values = c("LM Fit" = "red")) + 
      geom_abline(intercept = 0, slope = 1, linetype = 1, linewidth=1, color = "black") + 
    #scale_linetype_manual("", values = c("Perfect Fit" = 1)) +
    theme_minimal() + 
     theme(
       legend.position = "top", 
          legend.title = element_blank(),
       panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line = element_blank(),
          panel.border = element_blank()) + 
    labs(title = title1,
         x = xlab,
         y = ylab) +
    guides(fill = FALSE) 
}
```

#### a) Model Check by Comparing Results with Youssef

Below, we replicate the second simulation by Youssef and show that the results for the Mao model are identical.

```{r}
# The following code is used to find the optimal parameters and compute the test RMSE values. It's not evaluated at run. 
# The RMSE values are used in the following block to produce the graphs.
missingness = seq(.3,.9,.1)
RMSE_vals = rep(NA,length(missingness))
cv.out_list = list()

for(i in 1:length(missingness)){
  gen.dat <- generate_simulation_data_ysf(2,300,300,5,10,missing_prob = missingness[i])
  cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$W,
                   n_folds=5, 
                   lambda.1_grid = c(0),#seq(0,2,length=20),
                   lambda.2_grid = seq(.9, 0.1, length=20),
                   alpha_grid = c(1),#seq(0.992, 1, length=10),
                   numCores = 8,n1n2_optimized = TRUE,theta_estimator = theta_simple)
  
  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, cv.out$best_parameters$lambda.1, 
                     cv.out$best_parameters$lambda.2, cv.out$best_parameters$alpha, 
                     theta_estimator = theta_simple)
  cv.out_list[[i]] = cv.out
  RMSE_vals[i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
  print(i)
}
```


```{r eval=TRUE, fig.height=8, fig.width=6}
#2.087470 1.341574 1.259590 1.714914 2.180873 2.567561 2.859653 (theta_basic, optimized)
#3.311985 1.553556 1.282928 1.714914 2.180873 2.578329 2.865183
#[1] 1.137395 1.147916 1.194186 1.225637 1.306871 1.487800 1.904782
missingness = seq(.3,.9,.1)
RMSE_valus_theta_simple = c(3.047326, 3.048000, 3.032642, 3.036570, 3.038314, 3.043976,3.044622)
RMSE_vals_theta_random = c(2.108397, 1.375927, 1.259590, 1.714914, 2.180873, 2.567561,2.859653)
RMSE_vals_theta_default = c(1.137395, 1.147916, 1.194186, 1.225637, 1.306871, 1.487800, 1.904782)
data.frame(missingness=missingness, RMSE_vals1 = RMSE_vals_theta_random,
           RMSE_vals2=RMSE_vals_theta_default, RMSE_vals3 = RMSE_valus_theta_simple) %>% 
  ggplot(aes(x = missingness)) +
  geom_line(aes( y = RMSE_vals1, color="Proportion of Column")) + 
  geom_point(aes( y = RMSE_vals1), size = 3, shape=17) +
  geom_line(aes( y = RMSE_vals2, color="Logistic Model")) + 
  geom_point(aes( y = RMSE_vals2), size = 3, shape=17) +
  geom_line(aes( y = RMSE_vals3, color="Single Proportion")) + 
  geom_point(aes( y = RMSE_vals3), size = 3, shape=17) +
  theme_minimal() +  
  scale_color_manual(values = c("Proportion of Column" = "pink", "Logistic Model" = "red",
                                "Single Proportion"="cyan")) +
  labs(x = "missing %", y = "RMSE", title = "Model 2; n1=n2=300; m=5;", 
       subtitle = "RMSE on the missing data.", color="Theta Method") +
  theme(legend.position = "bottom")
```

Mao's logistic model surprisingly performed better than using the proportion of missing values. It will be used for the coming results.

#### b) Checking the quality of the estimates compared to the original values

```{r eval=TRUE, fig.height=10, fig.width=14}

graphs_A = list()
graphs_beta = list()
graphs_B = list()
mat_dim <- c(300, 500, 700)
results = data.frame(lambda_1=c(0,0,0), lambda_2=c(0.1842,0.142,0.142), alpha=c(1,1,1), dim=mat_dim, row.names = mat_dim)

for(i in 1:length(mat_dim)){
  gen.dat <- generate_simulation_data_ysf(2, results$dim[i],results$dim[i],5,5,0.5)
  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, 0.2,#results$lambda_1[i], 
                     results$lambda_2[i], results$alpha[i],n1n2_optimized = T)
  graphs_beta[[i]] = plot_actual.vs.estimated(gen.dat$beta.x,
                                              mao.out$beta_hat, "Beta", expression(hat("Beta")),title="")
  graphs_B[[i]] = plot_actual.vs.estimated(gen.dat$B[gen.dat$W==0], mao.out$B_hat[gen.dat$W==0], "B", expression(hat("B")),title="")
  graphs_A[[i]] = plot_actual.vs.estimated(gen.dat$A[gen.dat$W==0], mao.out$A_hat[gen.dat$W==0], "A", expression(hat("A")),title="")
}

combined_plot <- (graphs_A[[1]] | graphs_beta[[1]] | graphs_B[[1]]) / 
                 (graphs_A[[2]] | graphs_beta[[2]] | graphs_B[[2]]) / 
                 (graphs_A[[3]] | graphs_beta[[3]] | graphs_B[[3]]) +
                 plot_layout(guides = "collect") +
                 plot_annotation(title = "Comparing original and estimated values (Only data with W=0 is included)",
                                 subtitle = "with n1 = n2 = 300, 500, and 700; m=5, and probability of missingness is 0.5",)

combined_plot & theme(plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "lines"),legend.position = "none")
```

#### c) How is the proportion of missing data affects the optimal parameter values?

```{r}
alpha <- lambda.1 <- lambda.2 <- rep(0,length(missingness))
#0.1421053 0.1421053 0.1842105 0.1842105 0.2263158 0.3105263 0.4368421
for(i in 1:length(missingness)){
  alpha[i] = cv.out_list[[i]]$best_parameters$alpha
  lambda.1[i] = cv.out_list[[i]]$best_parameters$lambda.1
  lambda.2[i] = cv.out_list[[i]]$best_parameters$lambda.2
}
```


```{r eval=TRUE, fig.height=6, fig.width=8}

lambda.2 <- c(0.1421053, 0.1421053, 0.1842105, 0.1842105, 0.2263158, 0.3105263, 0.4368421)
alpha <- rep(1, length(missingness))
lambda.1 <- rep(0, length(missingness))

data.frame(missingness = rep(missingness,3), values=c(alpha,lambda.1,lambda.2), 
           labels=c(rep("Alpha",7),rep('Lambda 1',7), rep('Lambda 2',7))) %>%
  ggplot(aes(x = missingness, y = values, group = labels, color = labels, shape = labels)) +
  geom_line() +  # Add lines
  geom_point(size = 3) +  # Add points with a specified size
  scale_color_manual(values = c("Alpha" = "red", "Lambda 1" = "green", "Lambda 2" = "blue")) +
  scale_shape_manual(values = c("Alpha" = 17, "Lambda 1" = 15, "Lambda 2" = 18)) +
  theme_minimal() +  # Use a minimal theme
  labs(x = "missing %", y = "Hyperparameter value", title = "Hyperparameters vs missing percentage", 
       subtitle = "Settings are the same as the previous plot") +
  theme(legend.position = "bottom") 
```

In all of our simulations the optimal value for $\alpha$ was 1 and for $\lambda_1$ is 0. This removes the effect of the $L_2$-regularization and the loss function reduces to the following:

$$
\begin{aligned}
&f(\beta, B, \lambda_1, \lambda_2, \alpha) = \hat{R}^*(\beta,B) + \lambda_2 ||B||_*   \text{        }&&(e) \\
\end{aligned}
$$

#### d) How's changing the values of the hyperparameters affects the model?

In the simulation below, we set two hyparameters to their optimal values which changing the third within the recommended range and compute the test RMSE. This is repeated for the three parameters. The results confirms our observation that the optimal values for $\alpha$ and $\lambda_1$ are 1 and 0. 

```{r}
gen.dat <- generate_simulation_data_ysf(2,700,700,5,10,missing_prob = 0.6)
cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$W,
                   n_folds=5, 
                   lambda.1_grid = seq(0,2,length=20),
                   lambda.2_grid = seq(.9, 0.1, length=20),
                   alpha_grid = seq(0.992, 1, length=10),
                   numCores = 8,n1n2_optimized = FALSE,theta_estimator = theta_default)
#cv.out$best_parameters
```


```{r eval=TRUE, fig.height=6, fig.width=8}
optim_values = list(alpha=1, lambda.1=0, lambda.2=0.1421053)
#optim_values = list(alpha=1, lambda.1=0, lambda.2=0.1421053)


RMSE_vals = rep(NA, 30)
lambda.1 = seq(0,2,length=10)
lambda.2 = seq(.9, 0.1, length=10)
alpha = seq(0.992, 1, length=10)
for (i in 1:10){
  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, lambda.1[i], 
                     optim_values$lambda.2, optim_values$alpha)
  RMSE_vals[i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 

    mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, optim_values$lambda.1, 
                     lambda.2[i], optim_values$alpha)
  RMSE_vals[10+i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 

  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, optim_values$lambda.1, 
                       optim_values$lambda.2, alpha[i])
  RMSE_vals[20+i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
}


data.frame(RMSE=RMSE_vals, labels=rep(c("Lambda 1", "Lambda 2", "Alpha"),each=10),
           values=c(lambda.1, lambda.2, alpha)) %>%
  ggplot(aes(x = values, y = RMSE, group = labels, color = labels, shape = labels)) +
  geom_line() +  # Add lines
  geom_point(size = 3) +  # Add points with a specified size
  scale_color_manual(values = c("Alpha" = "red", "Lambda 1" = "green", "Lambda 2" = "blue")) +
  scale_shape_manual(values = c("Alpha" = 17, "Lambda 1" = 15, "Lambda 2" = 18)) +
  theme_minimal() +  # Use a minimal theme
  labs(x = "Hyperparameter value", y = "RMSE", title = "Hyperparameters change vs RMSE", 
       subtitle = "Model 2; n1=n2=700; m=5; RMSE on the missing data.") +
  theme(legend.position = "bottom")  
```









```{r}
gen.dat1 <- generate_simulation_data_mao()
gen.dat <- generate_simulation_data_ysf(2,300,300,10,10,missing_prob = 0.7)

cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$W,
                 n_folds=5, 
                 #lambda.1_grid = c(0),
                 lambda.1_grid = seq(0,2,length=20),
                 
                 lambda.2_grid = seq(.9, 0.1, length=20),
                 #lambda.2_grid = c(0.1842),
                 
                 alpha_grid = seq(0.992, 1, length=10),
                 #alpha_grid = c(0),
                 
                 numCores = 8,n1n2_optimized = TRUE);cv.out

mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, cv.out$best_parameters$lambda.1, 
                   cv.out$best_parameters$lambda.2, cv.out$best_parameters$alpha)

RMSE.A = sqrt(mean((gen.dat$A - mao.out$A_hat)^2)) 
Rank.diff = mao.out$rank - gen.dat$rank
RMSE.A
Rank.diff


```



```{r}
plot_actual.vs.estimated(gen.dat$beta, mao.out$beta_hat, expression(beta), expression(hat(beta)))
plot_actual.vs.estimated(gen.dat$B, mao.out$B_hat, "B", expression(hat("B")))
plot_actual.vs.estimated(gen.dat$A, mao.out$A_hat, "A", expression(hat("A")))
```


```{r eval=TRUE}

mat_dim <- c(300, 500, 700)
title = paste("Results on Model 2 (Yousef) with m=5, and probability of missingness is 0.5")
results = data.frame(lambda_1=c(0,0,0), lambda_2=c(0.1842,0.142,0.142), alpha=c(1,1,1), dim=mat_dim, row.names = mat_dim)

for(i in 1:length(mat_dim)){
  gen.dat <- generate_simulation_data_ysf(2, results$dim[i],results$dim[i],5,5,0.5)
  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, results$lambda_1[i], 
                     results$lambda_2[i], results$alpha[i])
  results$RMSE.A[i] = sqrt(mean((gen.dat$A - mao.out$A_hat)^2)) %>% round(4)
  results$RMSE.beta[i] = sqrt(mean((gen.dat$beta.x - mao.out$beta_hat)^2)) %>% round(4)
  results$RMSE.B[i] = sqrt(mean((gen.dat$B - mao.out$B_hat)^2)) %>% round(4)
  results$Rank[i] = gen.dat$rank
  results$Rank_estim[i] = mao.out$rank
}
results %>% dplyr::select(-dim) %>% 
   kable("html", caption = "Descriptive caption for your table") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


