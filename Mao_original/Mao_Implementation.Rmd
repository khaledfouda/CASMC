---
title: "Mao's Method Implementation"
output:
  html_document: default
  pdf_document: default
date: "2023-11-14"
editor_options: 
  chunk_output_type: inline
---



```{r setup, include=TRUE}
path_to_code <- "/mnt/campus/math/research/kfouda/main/HEC/Youssef/HEC_MAO_COOP/"
knitr::opts_chunk$set(echo = TRUE, eval = FALSE,  cache = TRUE)
knitr::opts_knit$set(root.dir=path_to_code)
```


```{r , include=TRUE, eval=TRUE, message=FALSE,warning=FALSE}
path_to_code = "./code_files/"
library(knitr)
library(kableExtra)
library(tidyverse)
library(magrittr)
require(foreach)
require(doParallel)
library(ggplot2)
library(hexbin)
library(patchwork)
```

## References:

1. Matrix Completion With Covariate Information by Xiaojun Mao et al.
2. Youssef's work (Document and code)

## Notes:
- Formulas with ids in the form ([0-9]*) have the same ids in Mao's paper.  


We consider a matrix of interest $A \in \Re^{n_1\times n_2}$ with row covariates $X  \in \Re ^{n_1 \times m}$ and the model

$$
A = X \beta + B
$$

where $B$ is a low rank matrix and orthogonal to $X$. 
We assume that we don't fully observe $A_0$ and that we have a slightly corrupted (and later, also partially observed when multiplied by $W$) version of it called $Y$.
This follows the model 

$$
Y_{ij} = A_{ij} + \epsilon_{ij}
$$

where $\epsilon_{ij}$ are i.i.d normal with 0 mean and finite variance.

We consider the sampling indicator $w_{ij}=1$ if $Y_{ij}$ is observed and 0 otherwise. $w_{ij}$ is independent from $\epsilon_{ij}$.

In Mao's paper, the the sampling (~~missingness~~inclusion) probabilities ($\theta_{ij}$) may depend on a subset of the covariates, and are modeled as 
$$ w_{ij} \sim Bernoulli(\theta_{ij}(x_i))$$
The loss function in (5) consists of the the minimizer $\hat{R}^*$, $L_2$ regularization on $\beta$ and $B$, and a $L_1$ regularization on $B$. 

$$
\begin{aligned}
&f(\beta, B, \lambda_1, \lambda_2, \alpha) = \hat{R}^*(\beta,B) + \lambda_1 ||\beta||^2_F + \lambda_2(\alpha ||B||_* + (1-\alpha||B||^2_F))  \text{        }&&(5) \\
&\hat{R}^*(\beta,B) = \frac{1}{n_1n_2} \{||X\beta - P_x \text{ } big(W*\hat\theta^**Y) ||^2_F+|| B - P_{\overline x}(W * \hat\theta^* * Y) ||^2_F \} && (4)
\end{aligned}
$$


In the code below, and based on the loss function defined in (5) and (4), we estimate $\beta$, $B$ using formulas (8) and (11) as written below:

$$
\begin{aligned}
\hat{\beta} &= (X^TX + n_1n_2\lambda_1 I_{m})^{-1} X^T (W * \hat\theta^* *Y)\text{        }&&(8)\\
\hat{B} &= \frac{1}{1+2(1-\alpha) n_1n_2\lambda_2} T_{\alpha n_1 n_2 \lambda_2}(P_{\overline x}(W * \hat\theta^* *Y))\text{        }&&(11)
\end{aligned}
$$
Where $\lambda_1,\lambda_2, \alpha$ are the regularization hyperparameters for $\beta$ and $B$, and
$$
\begin{aligned}
&T_c(D) = U \times Diag\{(\sigma_i-c)_+\}\times V^T\text{        }&&(b)\\
&P_{\overline x} = 1 - P_{X}\text{        }&&(c)\\
&P_{X} = X(X^TX)^{-1}X^T\text{        }&&(d)
\end{aligned}
$$
As for $\hat\theta^*$, we have three methods of estimating it where the first method is by fitting a logistic model assuming that the probabilities depend on some of the covariates, the second method uses the proportion of missing values within each column and the third method uses the proportion of missing values in the data.

$$
\begin{aligned}
 &\hat\theta^* = {\hat\theta_{ij}^{-1}(x_i) = {(expit((1,x_i^T)\gamma_{ij}))}^{-1}}\text{        }&&(a1)\\
 &\hat\theta^* = {\hat\theta_{ij}^{-1}(x_i) = (\frac{1}{n_1}\sum_{l=1}^{n_1}{I(W_{lj}=1)})^{-1} }\text{        }&&(a2)\\
 &\hat\theta^* = {\hat\theta_{ij}^{-1}(x_i) = (\frac{1}{n_1n_2}\sum_{l=1}^{n_1}\sum_{k=1}^{n_2}{I(W_{lk}=1)})^{-1} }\text{        }&&(a3)\\

\end{aligned}
$$
Where $\gamma_{ij}$ are the logistic model coefficients.

----------------------

## 1) Implementation with fixed $\lambda_1, \lambda_2,  \alpha$ 

The following function, $Mao.fit()$, estimates $\hat\beta$ and $\hat B$ as above with fixed (given) hyperparameters. I will try to use the same notations as above to avoid confusion.

```{r code=readLines(paste0(path_to_code, "/Mao_fit.R")),eval=TRUE}

```

```{r eval=TRUE}
# EDIT: These functions return the 1 / (probability of inclusion) NOT missingness.
theta_default <- function(X, W, ...){
  # using logistic regression as indicated in (a1)
  n1 = dim(W)[1]
  n2 = dim(W)[2]
  theta_hat = matrix(NA, n1, n2)
  for(j in 1:n2){
    model_data = data.frame(cbind(W[,j], X))
    model_fit = glm(X1~., family=binomial(), data=model_data)
    theta_hat[, j] = 1 / predict(model_fit, type="response")
  }
  return(theta_hat)
}
theta_random <- function(W, ...){
  # A theta estimation function that selects the proportion of missing data within the same column
  # using formula (a2)
  n1 = dim(W)[1]
  n2 = dim(W)[2]
  theta_hat = matrix(NA, n1, n2)
  for(j in 1:n2){
    theta_hat[,j] = n1 / sum(W[,j]==1) 
  }
  return(theta_hat)
}
theta_simple <- function(W, ...){
  # A theta estimation function that selects the proportion of missing data in the matrix
  # using formula (a3)
  n1 = dim(W)[1]
  n2 = dim(W)[2]
  theta_hat = matrix( (n1*n2) / sum(W==1), n1, n2)
  return(theta_hat)
}


Mao.fit <- function(Y, X, W, lambda.1, lambda.2, alpha, n1n2_optimized=TRUE, theta_estimator=theta_default){
  #
  #' ----------------------------------------------
  #' Input: Y: corrupted, partially observed A, (Y is assumed to be the product of Y*W)
  #'        W: Wij=1 if Aij is observed (ie, Yij !=0), and 0 otherwise
  #'         X: covariate matrix
  #'         lambda.1, lambda.2, alpha: hyperparameters
  #' ----------------------------------------------
  #' output: list of  A, Beta_hat, B_hat
  #' ----------------------------------------------
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  m  = dim(X)[2]
  # The following two lines are as shown in (c) and (d)
  X.X = t(X) %*% X
  P_X = X %*% solve(X.X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 
  
  if(n1n2_optimized == TRUE){
    # we define the factor that will be used later:
    n1n2 = svd(X.X)$d[1] 
  }else{
    n1n2 = n1 * n2
  }
  
  # The following part estimates theta (missingness probabilities)
  theta_hat = theta_estimator(W=W, X=X)
  # the following is the product of W * theta_hat * Y
  W_theta_Y = Y * theta_hat # * W 

  # beta hat as (8)
  beta_hat = solve(X.X + n1n2 * lambda.1 * diag(1, m)) %*% t(X) %*% W_theta_Y
  # SVD decomposition to be used in (b)
  svdd = svd(P_bar_X %*% W_theta_Y)
  if(n1n2_optimized == TRUE){
    # evaluation of  (b)
    n1n2 = svdd$d[1]
  }else{
    n1n2 = n1 * n2
  }
  T_c_D = svdd$u %*% (pmax(svdd$d - alpha*n1n2*lambda.2, 0) * t(svdd$v))
  # B hat as in (11)
  B_hat = (1 + 2 * (1-alpha) * n1n2 * lambda.2 )^(-1) * T_c_D
  # computing the rank of B [Copied from Mao's code; Don't understand how it works.]
  # EQUIVALENT to  qr(B_hat)$rank + m   or   qr(A_hat)$rank
  # B is a low rank matrix
  rank = sum(pmax(svdd$d - n1n2 * lambda.2 * alpha, 0) > 0) + m
  
  # Estimate the matrix as given in the model at the top
   A_hat = X %*% beta_hat + B_hat
  
  return(list(A_hat = A_hat, B_hat = B_hat, beta_hat = beta_hat, rank = rank))
}

```


-----------------------------------------------------------


## 2) Hyperparameter Optimization

Hyperparameter optimization for $\lambda_1,\lambda_2,\alpha$ is done using k-fold (k=5 by default) and grid search. Mao's paper optimizes for each parameter separately while fixing the other two. The explored/recommended the range of (0-2) for $\lambda_1$, (0.1,0.9) for $\lambda_2$, and (0.992,1) for $\alpha$.



```{r eval=TRUE}
prepare_fold_data <- function(Y, X, W, A, n1n2_optimized, theta_estimator) {
  n1 = dim(Y)[1]
  n2 = dim(Y)[2]
  m  = dim(X)[2]
  
  # The following two lines are as shown in (c) and (d)
  X.X = t(X) %*% X
  P_X = X %*% solve(X.X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 

  theta_hat = theta_estimator(W=W, X=X)
  
  #---------
  # The following are partial parts of equations 8 and 11 that don't involve the hyperparameters.
  # this is useful to avoid unneccessary matrix multiplications.
  #----------
  if(n1n2_optimized == TRUE){
    # this one is for equation 8, the product n1n2 is replace with the Eigen value
    n1n2Im = svd(X.X)$d[1]  * diag(1, m)  
  }else{
    n1n2Im = n1 * n2  * diag(1, m)
  }
  # the following is the product of W * theta_hat * Y
  W_theta_Y = Y * theta_hat
  X.W.theta.Y = t(X) %*% W_theta_Y
  svdd = svd(P_bar_X %*% W_theta_Y)
  if(n1n2_optimized == TRUE){
    # this one is for equation 11, the product is also replace with the Eigen value of the SVD
    n1n2 = svdd$d[1]
  }else{
    n1n2 = n1 * n2
  }
    
  return(list(A.test=A[W==0], W=W, X=X, X.X=X.X, n1n2Im=n1n2Im, n1n2=n1n2,
              X.W.theta.Y = X.W.theta.Y, svdd=svdd))
}

Mao.fit_optimized <- function(data, lambda.1, lambda.2, alpha){
  
  beta_hat = solve( data$X.X + data$n1n2Im * lambda.1) %*% data$X.W.theta.Y
  T_c_D = data$svdd$u %*% (pmax(data$svdd$d - alpha*data$n1n2*lambda.2, 0) * t(data$svdd$v))
  # B hat as in (11)
  B_hat = (1 + 2 * (1-alpha) * data$n1n2 * lambda.2 )^(-1) * T_c_D
  # Estimate the matrix as given in the model at the top
  A_hat = data$X %*% beta_hat + B_hat
  
  return(A_hat[data$W == 0])
}

# Computing the test error as given by Mao in page 205
test_error <- function(A.hat.test, A.test){
  return(sum( (A.hat.test-A.test)^2 )/ sum((A.test)^2))
}

```


```{r eval=TRUE}
Mao.cv <- function(A, X, Y, W, n_folds=5, lambda.1_grid = seq(0,1,length=30),
                   lambda.2_grid = seq(0.9, 0.1, length=30),
                   alpha_grid = seq(0.992, 1, length=20), seed=2023, numCores=16, n1n2_optimized=TRUE,
                   theta_estimator=theta_default){
  
  #' -------------------------------------------------------------------
  #' Input :
  #' A : Complete (True) A matrix as in the model above of size n1 by n2
  #' X :  Covariate matrix of size  n1 by m
  #' W : Binary matrix representing the mask. wij=1 if yij is observed. size similar to A
  #' The rest are cross validation parameters
  #' --------------------------------------------------------------------
  #' Output:
  #' list of best parameters and best score (minimum average MSE across folds)
  #' --------------------------------------------------------------------

  set.seed(seed = seed)
  indices = sample(cut(seq(1, nrow(A)), breaks=n_folds, labels=FALSE))
  best_score = Inf
  best_params = list(alpha = NA, lambda.1 = NA, lambda.2 = NA)
  
  fold_data = lapply(1:n_folds, function(i) {
    train_indices = which(indices != i, arr.ind = TRUE)
    Y_train = Y[train_indices,]
    X_train = X[train_indices,]
    W_train = W[train_indices,]
    A_train = A[train_indices,]
    prepare_fold_data(Y_train, X_train, W_train, A_train, n1n2_optimized, theta_estimator)
  })
  
  # Original for loop to be executed on one node 
  # *******************************************
  # for(alpha in alpha_grid){
  #   for(lambda.1 in lambda.1_grid){
  #     for(lambda.2 in lambda.2_grid){
  #       
  #       scores = numeric(n_folds)
  #       for(i in 1:n_folds){
  #         data = fold_data[[i]]
  #         #train_indices = which(indices != i, arr.ind=TRUE)
  #         
  #         # compute the estimates with a modified fit function
  #         A_hat = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
  #         #print(dim(A[test_indices,]))
  #         #print(dim(A_hat))
  #         #print(dim(data$X))
  #         # Evaluate model performance using MSE
  #         # IMPORTANT: As this is not a predictive model, the MSE is calculated on the training data
  #         # that is, the test fold isn't used at all.
  #         scores[i] = mean((data$A - A_hat)^2)
  #       }
  #       avg_score = mean(scores)
  #       
  #       if(avg_score < best_score){
  #         best_score = avg_score
  #         best_params = list(alpha=alpha, lambda.1=lambda.1, lambda.2=lambda.2)
  #       }
  #     }
  #   }
  # }
  # ************************************************************
  # prepare the cluster
  cl <- makeCluster(numCores) 
  registerDoParallel(cl)
  # fixing lambda 1 at 0 and optimizing for lambda 2 and alpha using a grid
  # Export the Mao.fit_optimized function and any other necessary objects to each worker
  clusterExport(cl, varlist = c("Mao.fit_optimized","test_error"))
  results <- foreach(alpha = alpha_grid, .combine = rbind) %:%
    foreach(lambda.2 = lambda.2_grid, .combine = rbind) %dopar% {
      lambda.1 = 0
      score = 0
      for (i in 1:n_folds) {
        data = fold_data[[i]]
        A_hat_test = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
        # scores[i] = mean((data$A.test - A_hat_test)^2)
        # -- EDIT: Using Mao's formula in page 205 to compute the test error
        score = score + test_error(A_hat_test, data$A.test)
      }
      #score = score / n_folds
      c(alpha, lambda.2, score)
    }
  # Process results to find the best parameters
  best_result <- results[which.min(results[, 3]), ]
  best_params <- list(alpha = best_result[1], lambda.1 = 0, lambda.2 = best_result[2])
  best_score <- best_result[3] / n_folds
  # close the cluster
  stopCluster(cl)
  #--------------------------------------------
  # fixing optimal values of lambda 2 and alpha and optimizing for lambda 1 separately
  lambda.2 = best_params$lambda.2
  alpha = best_params$alpha
  for(lambda.1 in lambda.1_grid){
    score = 0
    for(i in 1:n_folds){
      data = fold_data[[i]]
      # compute the estimates with a modified fit function
      A_hat_test = Mao.fit_optimized(data, lambda.1, lambda.2, alpha)
      # Evaluate model performance using MSE
      # IMPORTANT: As this is not a predictive model, the MSE is calculated on the training data
      # that is, the test fold isn't used at all.
      #scores[i] = mean((data$A.test - A_hat_test)^2)
      # -- EDIT: Using Mao's formula in page 205 to compute the test error
      score = score + test_error(A_hat_test, data$A.test)
    }
    score = score / n_folds

    if(score < best_score){
      best_score = score
      best_params$lambda.1 = lambda.1
    }
  }
  #---------------------------------------------------
  return(list(best_parameters = best_params, best_score = best_score))
  
}

```




### Notes regarding parts 1 and 2:

#### 1. $n_1*n_2$ alternative:
  
  I have tested both methods (using the actual $n_1*n_2$ and using the Eigen value formulas provided by Mao) and found that Mao's method     provided easier hyperparameter optimization. Changing method does not affect $\lambda_1$ and has a little but noticeable effect on $\alpha$. However, it has a strong effect on $\lambda_2$. For Mao's approach, the optimal $\lambda_2$ is always found somewhere between 0.1 and 0.9. However, when replacing it with $n_1*n_2$, the optimal $\lambda_2$ becomes very large. Cross-validation always selected the highest value of $\lambda_2$ provided. I stopped testing at $\lambda_2=100$ where the optimal value was still larger than that. 


#### 2. Grid optimization vs separate optimization:

  Mao's cross-validation function optimized each parameter separetly while I initially used a grid of the 3 parameters. To  compare the approaches, I fixed two parameters at optimal values and then optimized for the third. After that, I fixed them at non-optimal values and then optimized for the third. If the two results are equal, then the third parameter doesn't depend on the other two parameters. I found that $\lambda_1$ does not depend on either $\lambda_2$ or $\alpha$. However, $\lambda_2$ and $\alpha$ depend on the value of the other and hence needed to be optimized together. My final solution is to first set $\lambda_1=0$ (the reason is mentioned later) and optimized for $\lambda_2$ and $\alpha$ together using a grid. After finding their optimal values, I set them to their optimal values and optimize for $\lambda_1$. I used parallel computing (number of cores = 8 by default) for the grid optimization and a simple for loop for $\lambda_1$ optimization.

#### 3. Logistic Model for estimating the probabilities of missingness:

Mao's paper proposed a logistic model to estimate the probabilities of missingness using the matrix of covariates. His empirical study involved a dataset where these probabilities were dependent on some of the covariates (age group and gender). However, for genetic methylation, we don't expect that. I experimented with the suggested logistic model ($theta\_default()$), using the proportion of missing values within the same column ($theta\_random()$), and using a single value representing the proportion of missing values in the whole data ($theta\_simple()$). The results, shown in part (a) of the results section, shows that logistic model > proportion within column > proportion of all data.

#### 4. The subset used as a test set for validation: 

  K-fold cross-validation was used for optimization with a default of 5 folds. Since this is not a predictive model, it was not possible to apply the model on the test fold. Therefore, the score function (MSE) used the missing training values (ie, those with $W_{ij}=0$).

#### 5. Stanrdadization of rows and columns in the dataset

In our simulation and implementation we didn't consider to normalizing the rows and columns to 0 mean and unit variance, which is considered n Mao's paper. This is to be considered later. 

#### 6. *(NEW)* Rank of estimated matrices

The input matrices $A,\beta$ have ranks $min(n_1,n_2), m$ and $B$ has rank $m$ (default=5) for Youssef's simulation and $r$(default=10) for Mao's simulation. In both cases, $B$ is simulated as a low-rank matrix. The rank of $\hat{B}$ is increase by a factor of 3 or 4 depending on the simulation parameter but still far from being a full-rank.  The rank $\hat{\beta}$ is equal to the rank of $\beta$ and the rank of $\hat{A} = m + rank(\hat{B}) <<<< rank(A)$. For example, when $rank(A)=700$, $rank(\hat{A})=18$ (in Youssef's simulation). Below are the 18 non-zero singular values of $\hat{A}$ in that case, where we see a large drop in the values after the 6th singular value:

1131.3050162  221.6896957  215.9150270  211.6247514  203.9008080  196.4619305   26.7253143   17.9424518   15.0662677
14.2873524   10.4373681    8.3180618    7.9318012    6.1274801    5.1341907    1.9451653    1.8534295    0.5812634

Finally, in Mao's original simulation in the paper, the rank was also smaller in the cases where $\alpha=1$ and is doubled when $\alpha != 1$.

Next steps is to recreate Mao's simulation and investigate the rank more in depth. 


---------------------------------------------------------------------------


## 2) Simulation Test

For simulation, I was presented with 3 models, two defined by Youssef and one by Mao. I will show below the three models, and later for evaluation, I will use the second model by Youssef.

Using the same notations as before, Mao's simulation model is defined as:

$$
\begin{aligned}
Y = X \beta + B + \epsilon = A + \epsilon && (S0)
\end{aligned}
$$
Where $B = P_{\overline x} U V^T$ such that $U \in \Re^{n_1\times r}$ and $V \in \Re^{n_2\times r}$.
Moreover, $X, \beta, U,V \sim Gaussian(0,1)$. The error matrix $\epsilon \in \Re^{n_1\times n_2}\sim Gaussian(0,\sigma^2_\epsilon)$ with $\sigma^2_\epsilon$ is chosen such that the signal-to-noise ratio (SNR) is set to 1. That is

$$\sigma^2_\epsilon = \frac{\sum(A-\bar A)^2}{n_1n_2-1}$$
Finally, for their simulation, they set $m=20,r=10$ and explored the following values for the matrix dimensions $n1=n2=400,600,800,1000$.
 
 This simulation is defined below in the function $generate\_simulation\_data\_mao()$.
 
 Youssef's simulation involved row and column covariates to adapt to his data. The notations below are diffferent than those used by Youssef. I tried to standardize to Mao's notation style so we don't get confused. Youssef's two models are defined below:

 $$
 \begin{aligned}
 & Y = X \beta_x + (Z\beta_z)^T + P_{\overline x} BP_{\overline z} + \epsilon && (S1)\\
 & Y = X \beta_x + P_{\overline x} B + \epsilon&&(S2)
 \end{aligned} 
 $$
Clearly the first model employs row and column covariates while the second column employs only row covariates. $X \in \Re^{n_1\times m_1}$ will always be associated with row covariates while $Z \in \Re^{n_2\times m_2}$ will be associated with column covariates. 
The coefficients associated with each set of covariates are $\beta_x \in \Re^{m_1\times n_2}$ and $\beta_z \in \Re^{m_2\times n_1}$. The low rank matrix $B=B_xB_z$ is the product of matrices $B_x \in \Re^{n_1\times m_2}$ and $B_z \in \Re^{m_2\times n_2}$.
$X, Z, \epsilon \sim Gaussian(0,1)$ while $\beta_x, \beta_z, B_x, B_z \sim U(0,1)$
 
 For his simulation, he set $n_1=n_2=300$, $m_1=5$, $m_2=10$ and the missingness probability ranging from $30\%$ to $80\%$. Both models are defined in the function $generate\_simulation\_data\_ysf()$.
 
For the rest of this document, I will be using Youssef's second model (S2). 
 
 
```{r eval=TRUE}
normalize_matrix <- function(X) { # NOT USED FOR NOW
  # Normalize rows
  X_row_normalized <- t(apply(X, 1, function(row) {
    (row - mean(row)) / sd(row)
  }))
  
  # Normalize columns
  X_col_normalized <- apply(X_row_normalized, 2, function(col) {
    (col - mean(col)) / sd(col)
  })
  
  return(X_col_normalized)
}


# This function generates Mao's simulation as defined in (M0) above. Dimensions, missing probability are given as parameters. 
generate_simulation_data_mao <- function(n1 =400,  n2 = 400, m = 20, r = 10, MAR=TRUE, seed=2023){
  #' Input: 
  #'      n1, n2: are the dimensions of the A, Y, and B matrices
  #'      m: number of covariates
  #'      r: Second dimension of U and V where  B = P_bar_X U V^T
  #'      MAR: If True, missing at random method is employed to compute the missing probability and W
  #'      seed: random seed  
  set.seed(seed=seed)
  X <- matrix(rnorm(n1*m), ncol = m) #%>% normalize_matrix()
  beta <- matrix(rnorm(m*n2), ncol=n2)
  U <- matrix(rnorm(n1*r),ncol=r)
  V <- matrix(rnorm(n2*r),ncol=r)
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X 
  B = P_bar_X %*% U %*% t(V)
  A <- X %*% beta + B
  rank <- qr(A)$rank # = m + r
  #-----------------------------------------------------------------------------
  # Simulation Theta using missing-at-random MAR method
  gamma <- rbind( matrix(rnorm(1, -1.5, 0.1),1), matrix(rnorm(3, 0.3, 0.1),3))
  # only the first 3 columns of X are used
  # theta is the inverse of the probability of missingness following a logistic model 
  inclusion_prob = 1 / (1 + exp( -(cbind(1,X[,1:3]) %*% gamma)) ) #  all values should be close to 0.2
  theta = 1 / inclusion_prob
  # Wij=1 if A is observed following the probabilities of missingness defined above.
  W <- matrix( rbinom(n1*n2, 1, inclusion_prob ) , nrow = n1)
  # sum(W==0)/(n1*n2) should be equal to 0.2
  #----------------------------------------------------------
  # Does fully observed Y = A (ie,  without noise?)? In that case ignore the code below.
  #----------------------------------------------------------------------
  # Computing epsilon as iid zero mean Gaussian with variance chosen such that the signal-to-noise ratio (SNR) is 1
  signal_A <- sum((A - mean(A))^2) / (n1 * n2 - 1)
  sigma_epsilon <- sqrt(signal_A)  # Since SNR = 1
  epsilon <- matrix(rnorm(n1 * n2, mean = 0, sd = sigma_epsilon), n1, n2)
  #--------------------------------------------------------------------------------------------
  # Y is a corrupted, partially-observed version of A. Yij=0 for missing data [maybe consider making it NA]
  Y <- (A + epsilon) * W
  #---------------------------------------------------------------------
  return(list(A=A, W=W, X=X, Y=Y, beta=beta, B=B, theta=theta, gamma=gamma, inclusion_prob=inclusion_prob, rank=rank))
}
# This functions generates either model M1 or M2 from Yousef's simulation. Set model=1 for M1 or model=2 for M2.
generate_simulation_data_ysf <- function(model=1, n1 =300,  n2 = 300, m1 = 5, m2 = 10, missing_prob = 0.7,coll=FALSE,
                                         seed=2023){
  set.seed(seed=seed)
  X <- matrix(rnorm(n1*m1), ncol = m1)
  Z <- matrix(rnorm(n2*m2), ncol = m2)
  E <- matrix(rnorm(n1*n2), ncol = n2)
  # normalize X
  #X <- normalize_matrix(X)
  beta.x <- matrix(runif(m1*n2), ncol=n2)
  beta.z <- matrix(runif(m2*n1), ncol=n1)
  B.x <- matrix(runif(n1*m2), ncol=m2)
  B.z <- matrix(runif(m2*n2), ncol=n2)
  B <- B.x %*% B.z
  
  # if collinearity is needed, make the correlation between the first two columns in X and Z between (.99,1)
  # the actual correlation value is very close to 95%
  if(coll == TRUE){
    X[,2]  <- X[,1] + rnorm(n1, mean = 0, sd = 0.001)
    Z[,2]  <- Z[,1] + rnorm(n2, mean = 0, sd = 0.001)
  }
  
  
  P_X = X %*% solve(t(X) %*% X) %*% t(X)
  P_bar_X = diag(1,n1) - P_X
  P_Z = Z %*% solve(t(Z) %*% Z) %*% t(Z)
  P_bar_Z = diag(1,n2) - P_Z
  
  W <- matrix( rbinom(n1*n2, 1, (1 - missing_prob) ) , nrow = n1)
  
  if(model == 1){
    A <- (X %*% beta.x) + t(Z %*% beta.z) + P_bar_X %*% B %*% P_bar_Z 
    Y <- (A+E) * W
    rank <- qr(A)$rank
    return(list(A=A, W=W, X=X, Z=Z, beta.x=beta.x, beta.z=beta.z, B=B, rank=rank))
  }else if (model == 2){
    A <- (X %*% beta.x) + P_bar_X %*% B 
    Y <- (A + E) * W
    rank <- qr(A)$rank
    X <- matrix(rnorm(n1*m1), ncol = m1)
  Z <- matrix(rnorm(n2*m2), ncol = m2)
    return(list(A=A, W=W, X=X, Y=Y, beta.x=beta.x, B=B, rank=rank))
  }
  else{
    stop("Error: Unrecognized model.")
  }
  #-----------------------------------------------------------------------------
  #---------------------------------------------------------------------
  
}
```

## 3) Results:

The following function helps in comparing Actual vs Estimated values with a perfect-fit line and a linear-fit line. 

```{r eval=TRUE}
plot_actual.vs.estimated <- function(Actual, Predicted, xlab, ylab,title1="Comparison of Actual and Predicted Values"){
    
  data <- data.frame(
    Actual = as.vector(Actual),
    Predicted = as.vector(Predicted)
  )
  lm_fit <- lm(Predicted ~ Actual, data = data)
  coefficients <- coef(lm_fit)
  
  # Create the equation text
  equation_text <- sprintf("y = %.2fx + %.3f", coefficients[2], coefficients[1])
  
  ggplot(data, aes(x = Actual, y = Predicted)) + 
    geom_hex(color = "grey80",bins=200) +  
    geom_smooth(method = "lm", aes(color = "LM Fit"), se = TRUE) +
    #geom_line(data = data.frame(x = range(data$Actual), y = range(data$Predicted)),
    #          aes(x = x, y = y, linetype = "Perfect Fit"), alpha=0, color = "white") +  
    annotate("text", x = Inf, y = Inf, label = equation_text, hjust = 2.1, size=5, vjust = 3.5, color = "red", size = 2.5) + 
    scale_color_manual("", values = c("LM Fit" = "red")) + 
      geom_abline(intercept = 0, slope = 1, linetype = 1, linewidth=1, color = "black") + 
    #scale_linetype_manual("", values = c("Perfect Fit" = 1)) +
    theme_minimal() + 
     theme(
       legend.position = "top", 
          legend.title = element_blank(),
       panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line = element_blank(),
          panel.border = element_blank()) + 
    labs(title = title1,
         x = xlab,
         y = ylab) +
    guides(fill = FALSE) 
}
```

#### Generating Mao's simulations from table 1 page 206

```{r}
dimensions = c(400, 600, 800, 1000)
RMSE_A <- RMSE_beta <- RMSE_B <- test_errors <- rank <- rep(0,4)
best_params_list = list()
B = 30 # number of simulations to run.
# i = 1
for(b in 1:B){
  for(i in 1:4){
    gen.dat <- generate_simulation_data_mao(n1=dimensions[i],n2=dimensions[i],m=5,r=10, seed=b)
    cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$Y, gen.dat$W,
                     n_folds=5, 
                     lambda.1_grid = seq(0,2,length=20),
                     lambda.2_grid = seq(.9, 0, length=10),
                     alpha_grid = seq(0.992, 1, length=10),
                     numCores = 4,n1n2_optimized = TRUE,theta_estimator = theta_default,seed = b)
    
    mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, cv.out$best_parameters$lambda.1,  
                       cv.out$best_parameters$lambda.2, cv.out$best_parameters$alpha, 
                       theta_estimator = theta_default)
    best_params_list[[i]] =  cv.out$best_parameters
    test_errors[i] = test_errors[i] + test_error(mao.out$A_hat[gen.dat$W==0], gen.dat$A[gen.dat$W==0])
    RMSE_A[i] = RMSE_A[i] + sqrt(mean((gen.dat$A - mao.out$A_hat)^2))
    RMSE_beta[i] = RMSE_beta[i] + sqrt(mean((gen.dat$beta - mao.out$beta_hat)^2))
    RMSE_B[i] = RMSE_B[i] + sqrt(mean((gen.dat$B - mao.out$B_hat)^2))
    rank[i] = rank[i] +  mao.out$rank
    print(i) 
    #print(cv.out$best_parameters)
  }
  print(paste(".....",b,"....")) 
}
RMSE_A <- RMSE_A / B 
RMSE_beta <- RMSE_beta / B                                        
RMSE_B <- RMSE_B / B 
test_errors <- test_errors / B                     
rank <- rank / B   


results <- data.frame(dimension=dimensions, RMSE_A=RMSE_A, RMSE_beta=RMSE_beta, RMSE_B=RMSE_B, test_error=test_errors,
           rank=rank,
           alpha=unlist(sapply(best_params_list, function(x) x$alpha)), 
           lambda_1=unlist(sapply(best_params_list, function(x) x$lambda.1)),
           lambda_2=unlist(sapply(best_params_list, function(x) x$lambda.2)))
write.csv(results, file = "sim_results_MAO_table1_B30_2.csv", row.names = FALSE)

```

```{r eval=TRUE}

results <- read.csv("sim_results_MAO_table1_B30_1.csv")
#results
kable(results,format = "pipe")
```



#### a) Model Check by Comparing Results with Youssef

Below, we replicate the second simulation by Youssef and show that the results for the Mao model are identical.

```{r}
# The following code is used to find the optimal parameters and compute the test RMSE values. It's not evaluated at run. 
# The RMSE values are used in the following block to produce the graphs.
missingness = seq(.3,.9,.1)

thetas = list(theta_default, theta_simple, theta_random)
names = c("theta_default", "theta_simple", "theta_random")
for(t in 2:3){
  RMSE_vals <- test_errors <- rep(NA,length(missingness))
  cv.out_list = list()
  for(i in 1:length(missingness)){
    gen.dat <- generate_simulation_data_ysf(2,300,300,5,10, missing_prob = missingness[i],coll=TRUE)
    cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$Y, gen.dat$W,
                     n_folds=5, 
                     lambda.1_grid = seq(0,2,length=20),
                     lambda.2_grid = seq(.9, 0, length=20),
                     alpha_grid = seq(0.992, 1, length=10),
                     numCores = 8,n1n2_optimized = TRUE,theta_estimator = thetas[[t]])
    
    mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, cv.out$best_parameters$lambda.1, 
                       cv.out$best_parameters$lambda.2, cv.out$best_parameters$alpha, 
                       theta_estimator = thetas[[t]])
    cv.out_list[[i]] = cv.out
    test_errors[i] = test_error(mao.out$A_hat[gen.dat$W==0], gen.dat$A[gen.dat$W==0])
    RMSE_vals[i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
    print(i)
    #print(cv.out$best_parameters)
  }
  
  output <- data.frame(method = names[t], missingness = missingness, 
               test_errors=test_errors, RMSE_A=RMSE_vals, 
               lambda.2 = unlist(sapply(cv.out_list, function(x) x$best_parameters$lambda.2)),
               lambda.1 = unlist(sapply(cv.out_list, function(x) x$best_parameters$lambda.1)),
               alpha = unlist(sapply(cv.out_list, function(x) x$best_parameters$alpha)))
  
  write.csv(output, paste0("a_",names[t],"_1_.csv"), row.names = F)
}
```


```{r eval=TRUE, fig.height=6, fig.width=8}
missingness = seq(.3,.9,.1)
names = c("theta_default", "theta_simple", "theta_random")



results <- rbind( read.csv(paste0("a_",names[1],"_.csv")) %>% mutate(label="Logistic model"),
                  read.csv(paste0("a_",names[2],"_.csv")) %>% mutate(label="Proportion within column"),
                  read.csv(paste0("a_",names[3],"_.csv")) %>% mutate(label="Proportion overall")) 
                  

results %>%
  ggplot(aes(x = missingness, y=test_errors, group=label, color=label)) +
  geom_line() + 
  geom_point(size = 3, shape=17) +
  theme_bw() +  
  scale_color_manual(values = c("red","pink", "cyan")) +
  labs(x = "missing %", y = "RMSE", title = "Model 2; n1=n2=300; m=5;", 
       subtitle = "RMSE on the missing data.", color="Theta Method") +
  theme(legend.position = "bottom") 
```



Mao's logistic model surprisingly performed better than using the proportion of missing values. It will be used for the coming results.

#### b) Checking the quality of the estimates compared to the original values

```{r eval=TRUE, fig.height=10, fig.width=14}

graphs_A = list()
graphs_beta = list()
graphs_B = list()
part_b_data <- read.csv("sim_results_MAO_table1_B30_1.csv")[c(1,3,4),]



for(i in 1:nrow(part_b_data)){
  gen.dat <- generate_simulation_data_mao(part_b_data$dimension[i],part_b_data$dimension[i])
  #gen.dat <- generate_simulation_data_ysf(2, results$dim[i],results$dim[i],5,5,0.5)
  mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, part_b_data$lambda_1[i], 
                     part_b_data$lambda_2[i], part_b_data$alpha[i],n1n2_optimized = T,theta_estimator = theta_default)
  graphs_beta[[i]] = plot_actual.vs.estimated(gen.dat$beta, mao.out$beta_hat, "Beta", expression(hat("Beta")),title="")
  graphs_B[[i]] = plot_actual.vs.estimated(gen.dat$B[gen.dat$W==0], mao.out$B_hat[gen.dat$W==0], "B", expression(hat("B")),title="")
  graphs_A[[i]] = plot_actual.vs.estimated(gen.dat$A[gen.dat$W==0], mao.out$A_hat[gen.dat$W==0], "A", expression(hat("A")),title="")
}

combined_plot <- (graphs_A[[1]] | graphs_beta[[1]] | graphs_B[[1]]) / 
                 (graphs_A[[2]] | graphs_beta[[2]] | graphs_B[[2]]) / 
                 (graphs_A[[3]] | graphs_beta[[3]] | graphs_B[[3]]) +
                 plot_layout(guides = "collect") +
                 plot_annotation(title = "Comparing original and estimated values (Only data with W=0 is included)",
                                 subtitle = "with n1 = n2 = 300, 500, and 700; m=5, and probability of missingness is 0.8",)

combined_plot & theme(plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "lines"),legend.position = "none") 
```


#### c) How is the proportion of missing data affects the optimal parameter values?


```{r eval=TRUE, fig.height=6, fig.width=8}
names = c("theta_default", "theta_simple", "theta_random")
results <- rbind( read.csv(paste0("a_",names[1],"_.csv")) %>% mutate(label="Logistic model"),
                  read.csv(paste0("a_",names[2],"_.csv")) %>% mutate(label="Proportion within column"),
                  read.csv(paste0("a_",names[3],"_.csv")) %>% mutate(label="Proportion overall")) 
                  

results %>%
  ggplot(aes(x = missingness)) +
   geom_line(aes( y = alpha, color="Alpha")) + 
  geom_point(aes( y = alpha), size = 3) +
  geom_line(aes( y = lambda.1, color="Lambda 1")) + 
  geom_point(aes( y = lambda.1), size = 3) +
  geom_line(aes( y = lambda.2, color="Lambda 2")) + 
  geom_point(aes( y = lambda.2), size = 3) +
  theme_bw() +  
  scale_color_manual(values = c("Alpha" = "darkgreen", "Lambda 1" = "darkred",
                                "Lambda 2"="darkblue")) +
  scale_shape_manual(values = c("Alpha" = 17, "Lambda 1" = 15, "Lambda 2" = 18)) +
  labs(x = "missing %", y = "Parameter Value", title = "Hyperparameters vs missing percentage", 
       subtitle = "Settings are the same as the previous plot", color="Hyperparameter") +
  theme(legend.position = "bottom") +
  facet_wrap(~label)
```




In almost all of our simulations the optimal value for $\alpha$ was 1. This removes the effect of the $L_2$-regularization on B and the loss function reduces to the following:

$$
\begin{aligned}
&f(\beta, B, \lambda_1, \lambda_2, \alpha) = \hat{R}^*(\beta,B) + \lambda_1 ||\beta||^2_F + \lambda_2 ||B||_*   \text{        }&&(e) \\
\end{aligned}
$$

#### d) How's changing the values of the hyperparameters affects the model?

In the simulation below, we set two hyparameters to their optimal values which changing the third within the recommended range and compute the test RMSE. This is repeated for the three parameters. The results confirms our observation that the optimal values for $\alpha$ and $\lambda_1$ are 1 and 0. 

```{r}
gen.dat <- generate_simulation_data_ysf(2,700,700,8,8,missing_prob = 0.6,coll = T)
cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$W,
                   n_folds=5, 
                   lambda.1_grid = seq(0,2,length=20),
                   lambda.2_grid = seq(.9, 0.1, length=20),
                   alpha_grid = seq(0.992, 1, length=10),
                   numCores = 8,n1n2_optimized = TRUE,theta_estimator = theta_default)
cv.out$best_parameters
```


```{r}
#optim_values = list(alpha=0.992, lambda.1=0, lambda.2=0.9)
optim_values = list(alpha=1, lambda.1=0, lambda.2=0.1421053)

part_d_data <- read.csv("sim_results_MAO_table1_B30_1.csv")[c(3),]


RMSE_vals = rep(NA, 30)
lambda.1 = seq(0,2,length=10)
lambda.2 = seq(.9, 0.1, length=10)
alpha = seq(0.992, 1, length=10)

gen.dat <- generate_simulation_data_mao(part_d_data$dimension[1],part_d_data$dimension[1])

for (i in 1:10){
  mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, lambda.1[i], 
                   part_d_data$lambda_2[1], part_d_data$alpha[1],n1n2_optimized = T,theta_estimator = theta_default)
  
  RMSE_vals[i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
  mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, part_d_data$lambda_1[1], 
                   lambda.2[i], part_d_data$alpha[1],n1n2_optimized = T,theta_estimator = theta_default)
  
  RMSE_vals[10+i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
  
    mao.out <- Mao.fit(gen.dat$Y, gen.dat$X, gen.dat$W, part_d_data$lambda_1[1], 
                   part_d_data$lambda_2[1], alpha[i],n1n2_optimized = T,theta_estimator = theta_default)
  RMSE_vals[20+i] = sqrt(mean((gen.dat$A[gen.dat$W==0] - mao.out$A_hat[gen.dat$W==0])^2)) 
}

saveRDS(RMSE_vals, "part_d_data.rds")
```


```{r eval=TRUE, fig.height=6, fig.width=8}
RMSE_vals = readRDS("part_d_data.rds")
lambda.1 = seq(0,2,length=10)
lambda.2 = seq(.9, 0.1, length=10)
alpha = seq(0.992, 1, length=10)

data.frame(RMSE=RMSE_vals, labels=rep(c("Lambda 1", "Lambda 2", "Alpha"),each=10),
           values=c(lambda.1, lambda.2, alpha)) %>%
  ggplot(aes(x = values, y = RMSE, group = labels, color = labels, shape = labels)) +
  geom_line() +  # Add lines
  geom_point(size = 3) +  # Add points with a specified size
  scale_color_manual(values = c("Alpha" = "red", "Lambda 1" = "green", "Lambda 2" = "blue")) +
  scale_shape_manual(values = c("Alpha" = 17, "Lambda 1" = 15, "Lambda 2" = 18)) +
  theme_minimal() +  # Use a minimal theme
  labs(x = "Hyperparameter value", y = "RMSE", title = "Hyperparameters change vs RMSE", 
       subtitle = "Model 2; n1=n2=700; m=5; RMSE on the missing data.") +
  theme(legend.position = "bottom")  
  
```









```{r}
gen.dat1 <- generate_simulation_data_mao()
gen.dat <- generate_simulation_data_ysf(2,300,300,10,10,missing_prob = 0.7)

cv.out <- Mao.cv(gen.dat$A, gen.dat$X, gen.dat$W,
                 n_folds=5, 
                 #lambda.1_grid = c(0),
                 lambda.1_grid = seq(0,2,length=20),
                 
                 lambda.2_grid = seq(.9, 0.1, length=20),
                 #lambda.2_grid = c(0.1842),
                 
                 alpha_grid = seq(0.992, 1, length=10),
                 #alpha_grid = c(0),
                 
                 numCores = 8,n1n2_optimized = TRUE);cv.out

mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, cv.out$best_parameters$lambda.1, 
                   cv.out$best_parameters$lambda.2, cv.out$best_parameters$alpha)

RMSE.A = sqrt(mean((gen.dat$A - mao.out$A_hat)^2)) 
Rank.diff = mao.out$rank - gen.dat$rank
RMSE.A
Rank.diff


```



```{r}
plot_actual.vs.estimated(gen.dat$beta, mao.out$beta_hat, expression(beta), expression(hat(beta)))
plot_actual.vs.estimated(gen.dat$B, mao.out$B_hat, "B", expression(hat("B")))
plot_actual.vs.estimated(gen.dat$A, mao.out$A_hat, "A", expression(hat("A")))
```


```{r }

mat_dim <- c(300, 500, 700)
title = paste("Results on Model 2 (Yousef) with m=5, and probability of missingness is 0.5")
results = data.frame(lambda_1=c(0,0,0), lambda_2=c(0.1842,0.142,0.142), alpha=c(1,1,1), dim=mat_dim, row.names = mat_dim)

for(i in 1:length(mat_dim)){
  gen.dat <- generate_simulation_data_ysf(2, results$dim[i],results$dim[i],5,5,0.5)
  mao.out <- Mao.fit(gen.dat$A*gen.dat$W, gen.dat$X, results$lambda_1[i], 
                     results$lambda_2[i], results$alpha[i])
  results$RMSE.A[i] = sqrt(mean((gen.dat$A - mao.out$A_hat)^2)) %>% round(4)
  results$RMSE.beta[i] = sqrt(mean((gen.dat$beta.x - mao.out$beta_hat)^2)) %>% round(4)
  results$RMSE.B[i] = sqrt(mean((gen.dat$B - mao.out$B_hat)^2)) %>% round(4)
  results$Rank[i] = gen.dat$rank
  results$Rank_estim[i] = mao.out$rank
  results$Rank_A[i] = qr(mao.out$A_hat)$rank
}
results %>% dplyr::select(-dim) %>% 
   kable("html", caption = "Descriptive caption for your table") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


